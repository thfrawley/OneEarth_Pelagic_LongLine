***NOTE THAT ALL CODE WAS DEVELOPED AND TESTED WITH THE PACKAGE VERSIONS REFERENCED BELOW and R-4.0.5***

Step 1A.1: Set Directory and Load Packages
```{r, warning=FALSE, message=FALSE}

rm(list=ls())

### Change to the directory on your local machine where the files for this process are being stored
knitr::opts_knit$set(root.dir = "C:/Users/timot/Desktop/Code_Sharing") 

### Packages will need to be installed your first run through
library(sf)   ###Version 0.9-8
library(raster)   ###Version 3.4-5
library(dplyr)   ###Version 1.05
library(rgeos)   ###Version  0.5-5
library(ggplot2)   ###Version 3.3.3
library(data.table)   ###Version 1.14.0
library(forcats)   ###Version 0.5.1
library(reshape2)   ###Version 1.4.4
library(purrr)   ###Version 0.3.4
library(distances)   ###Version 0.1.8
library(cluster)   ###Version 2.1.1
library(tidyr)   ###Version 1.1.3
library(parallel)   ###Version 1.24.0
library(furrr)   ###Version  0.2.2
library(lubridate)   ###Version 1.7.10
library(tidyverse)   ###Version 1.3.0
library(tictoc)   ###Version 1.0
library(maptools)   ###Version 1.1-1
library(rgdal)   ###Version 1.5-23

```


STEP 1A.2: Load in Shapefile Templates
```{r}

Map<-read_sf('Shapefiles/Pacific_Landmasses.shp')
IATTC<-read_sf("Shapefiles/IATTC.shp")
WCPFC<-read_sf('Shapefiles/WCPFC.shp')


###Chunk of code that centers RFMO Bounds on the Pacific and combines them
Pacific_IATTC<-st_shift_longitude(IATTC)
Pacific_WCPFC<-st_shift_longitude(WCPFC)

Convention_Areas<-rbind(IATTC, WCPFC)
Convention_Areas$area <- st_area(Convention_Areas)
Combined_Convention_Bounds <- Convention_Areas %>% summarise(area = sum(area))

Pacific_Convention_Areas<-rbind(Pacific_IATTC, Pacific_WCPFC)
Pacific_Convention_Areas$area <- st_area(Pacific_Convention_Areas)
Pacific_Combined_Convention_Bounds <- Pacific_Convention_Areas %>% summarise(area = sum(area))

###Plot up the Combined Convention Bounds to make sure things look good
ggplot() +
  geom_sf(data=Map) +
  geom_sf(data=Pacific_Combined_Convention_Bounds, fill=NA) +
  theme_bw()

```


Step 1A.3: Load in AIS Data from Daily .csv Files, Subset to Retain LL vessels, & Clip to Study Extent 
```{r warning=FALSE, message=FALSE}


###Name the Data Directory where you have the Unprocessed Data Stored
data_dir <- 'C:/Users/timot/Desktop/Code_Sharing/Unprocessed_Data/Unprocessed_GFW_AIS_Data/'

###Input .csv Files Downloaded from GFW Website:
###https://globalfishingwatch.org/data-download/datasets/public-fishing-effort
###Data Processing Code Adapted From GFW Website:
###https://globalfishingwatch.org/data/working-with-our-downloadable-public-data-in-r/
###Be sure to specify the year and corresponding dates of the data you want to process 

effort_files <- tibble(
  file = list.files(paste0(data_dir, 'mmsi-daily-csvs-10-v2-2017'), 
                    pattern = '.csv', recursive = T, full.names = T),
  date = ymd(str_extract(file, 
                         pattern = '[[:digit:]]{4}-[[:digit:]]{2}-[[:digit:]]{2}')))
effort_dates <- seq(ymd('2017-01-01'), ymd('2017-12-31'), by='days')
effort_files <- filter(effort_files, date %in% effort_dates)

plan(multisession) 
effort_df <- furrr::future_map_dfr(effort_files$file, .f = read_csv)


effort_df$fishing_hours <- format(round(effort_df$fishing_hours, 2), nsmall = 2)
effort_df$fishing_hours <- as.numeric(effort_df$fishing_hours)
effort_df$hours <- format(round(effort_df$hours, 2), nsmall = 2)
effort_df$hours <- as.numeric(effort_df$hours)

###Only retain records associated with drifting longline vessels
registry<-read.csv('fishing-vessels-v2.csv')
registry<-registry[which(registry$vessel_class_gfw=="drifting_longlines"),]
flag_registry<-registry[c(1,4)]


Single_Gear<-as.data.frame(unique(registry$mmsi))
names(Single_Gear)<-c("mmsi")
effort_df<-setDT(effort_df)[mmsi %chin% Single_Gear$mmsi] 

###Shift Longitude to center on pacific

recenter_lon <- function(lon) { 
  lon <- ifelse(lon <= 0,180+(180-abs(lon)),lon)
  return(lon)                               
}

effort_df$cell_ll_lon<-recenter_lon(effort_df$cell_ll_lon) 

####Clip by Combined Convention Bounds; This Will Take Quite A While
Fishing_Data <- st_as_sf(effort_df, coords = c('cell_ll_lon', 'cell_ll_lat'), crs = "+init=epsg:4326")
Fishing_Data<-st_intersection(Fishing_Data, Pacific_Combined_Convention_Bounds)
Lon_Lat_Coords<-as.data.frame(st_coordinates(Fishing_Data))
names(Lon_Lat_Coords)<-c("Lon","Lat")
Fishing_Data<-as.data.frame(Fishing_Data)
Fishing_Data<-cbind(Fishing_Data, Lon_Lat_Coords)
Fishing_Data<- Fishing_Data[c(-5,-6)]
Fishing_Data$date<-as.character(Fishing_Data$date)
```

Output Here If You Want Data at the Native Resolution After Clipping and Sub-setting
```{r}
##write.csv(Fishing_Data, "2017_V2_LL_Pacific.csv", row.names=FALSE)
```

Step 1A.4 Aggregate Data at .25 Degree Resolution For Data Visualization & Final Figures (Not Necessary For Clustering) 
```{r warning=FALSE, message=FALSE}

###Load in and crop a Pacific Ocean Template
Pacific<-read_sf('Shapefiles/Pacific_Ocean.shp')
Pacific_Simp<-st_simplify(Pacific, dTolerance = .25)
r<-raster(Pacific_Simp)
res(r)<-.25
r<-rasterize(Pacific_Simp, r)

###Nudges Data Points From the Corners So That They Fall Within The Fishnet We Are Creating
Fishing_Data$Lon<-Fishing_Data$Lon +.04
Fishing_Data$Lat<-Fishing_Data$Lat +.04

Fishing_Data$date<-as.character(Fishing_Data$date)
Fishing_Data<-Fishing_Data[which(Fishing_Data$fishing_hours > 0),]

###Start Aggregation Fishnet LOOP, This Will Take Quite Awhile

ships <-as.data.frame(unique(Fishing_Data$mmsi)) 
names(ships) <- c("mmsi")
List_Ships<-as.list(as.character(ships$mmsi))
coarse_res_Fishing_Data<-NULL

tic()

for (i in 1:length(List_Ships)){
  Ship = List_Ships[i]
  print(Ship)
  ship_fishing_data<-Fishing_Data[which(Fishing_Data$mmsi==Ship),]
  time <-as.data.frame(unique(ship_fishing_data$date))                        
  names(time) <- c("date")
  List_Time<-as.list(as.character(time$date))
  coarse_res<-NULL        

for (i in 1:length(List_Time)){
  Time = List_Time[i]
  Single_Step<- ship_fishing_data[which(ship_fishing_data$date == Time),]
  asp<-SpatialPoints(Single_Step[,5:6],
    proj4string=CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
  asp <- SpatialPointsDataFrame(asp, Single_Step)
  catch<-rasterize(coordinates(asp), r, asp$fishing_hours, fun='sum', background=0)
  coords <- as.matrix(coordinates(catch))
  df <- data.frame(Longitude = coords[, 1], Latitude = coords[, 2], as.data.frame(catch))
  df<-df[which(df$layer > 0 ),]
  df$Time<-Time
  coarse_res<-rbind(coarse_res, df)
}

names(coarse_res)<- c("Lon","Lat", "fishing_hours", "date")
coarse_res$mmsi<-Ship
coarse_res_Fishing_Data<-rbind(coarse_res_Fishing_Data, coarse_res)

}

coarse_res_Fishing_Data$date<-as.character(coarse_res_Fishing_Data$date)
coarse_res_Fishing_Data$mmsi<-as.character(coarse_res_Fishing_Data$mmsi)

toc()
```


Output Here If You Want Data at the Aggregate Resolution After Clipping and Sub-setting
```{r}
##write.csv(coarse_res_Fishing_Data, "2017_V2_LLP_fh_0.25.csv", row.names=FALSE)
```


